{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization using Keras and the scikit-learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Keras, we can implement a grid search over hyperparameters using the scikit-learn API.\n",
    "\n",
    "We will demonstrate this using the original regression example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important hyperparameters for training\n",
    "\n",
    "- optimization algorithm\n",
    "- learning rate\n",
    "- dropout\n",
    "- regularization\n",
    "- batch size\n",
    "- number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As examples of grid search, we will explore varying optimizers, number of epochs, learning rate, and regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# default settings\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some housekeeping\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1 # for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's do a grid search over optimization algorithms.\n",
    "\n",
    "For some optimizers, dependent parameters can/should be tuned. We'll explore that later (by example).\n",
    "For most optimizers, it is in fact recommended to NOT change the defaults (e.g., RMSprop, Adagrad...)\n",
    "\n",
    "For this run, the defaults will be used, e.g.\n",
    "- SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "- Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "- RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build_fn for keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params)\n",
    "def create_model(optimizer = \"Adam\"):    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal')) # activation = None for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# epochs will be passed through to scikit-learn\n",
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "optimizers = ['RMSprop', 'Adam', 'SGD']\n",
    "grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(optimizer = optimizers))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_cv_results(fit):\n",
    "    means = fit.cv_results_['mean_test_score']\n",
    "    sdevs = fit.cv_results_['std_test_score']\n",
    "    params = fit.cv_results_['params']\n",
    "    for mean, sd, param in zip(means, sdevs, params):\n",
    "        print(\"Mean score: {:.2f}    Std. dev.: {:.2f}    Param: {}\".format(mean, sd, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 539.73    Std. dev.: 59.95    Param: {'optimizer': 'RMSprop'}\n",
      "Mean score: 541.01    Std. dev.: 60.05    Param: {'optimizer': 'Adam'}\n",
      "Mean score: 21.57    Std. dev.: 7.49    Param: {'optimizer': 'SGD'}\n"
     ]
    }
   ],
   "source": [
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly, with 50 epochs of training, SGD is _much_ better than the other algorithms! Let's check if Adam and RMSprop catch up with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer = \"SGD\", epochs = num_epochs):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal')) # activation = None for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 23.43    Std. dev.: 4.69    Param: {'optimizer': 'SGD', 'epochs': 50}\n",
      "Mean score: 549.24    Std. dev.: 39.39    Param: {'optimizer': 'RMSprop', 'epochs': 50}\n",
      "Mean score: 550.84    Std. dev.: 41.40    Param: {'optimizer': 'Adam', 'epochs': 50}\n",
      "Mean score: 23.57    Std. dev.: 4.09    Param: {'optimizer': 'SGD', 'epochs': 100}\n",
      "Mean score: 519.33    Std. dev.: 38.36    Param: {'optimizer': 'RMSprop', 'epochs': 100}\n",
      "Mean score: 520.28    Std. dev.: 38.72    Param: {'optimizer': 'Adam', 'epochs': 100}\n",
      "Mean score: 23.35    Std. dev.: 4.02    Param: {'optimizer': 'SGD', 'epochs': 150}\n",
      "Mean score: 494.68    Std. dev.: 35.99    Param: {'optimizer': 'RMSprop', 'epochs': 150}\n",
      "Mean score: 496.45    Std. dev.: 35.88    Param: {'optimizer': 'Adam', 'epochs': 150}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "optimizers = ['SGD', 'RMSprop', 'Adam']\n",
    "epochs = [50,100,150]\n",
    "# Let's choose 3 cv splits to speed this up for the demo\n",
    "# grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(optimizer = optimizers, epochs = epochs))\n",
    "grid = GridSearchCV(estimator=model, cv=3, param_grid=dict(optimizer = optimizers, epochs = epochs))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)\n",
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doesn't help. How about varying the learning rate for Adam (default is 0.001)?\n",
    "(We will just pick Adam for this run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(learn_rate = learning_rate):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal')) # activation = None for regression\n",
    "    optimizer = Adam(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 551.62    Std. dev.: 40.72    Param: {'learn_rate': 0.001}\n",
      "Mean score: 369.29    Std. dev.: 25.89    Param: {'learn_rate': 0.01}\n",
      "Mean score: 24.21    Std. dev.: 4.94    Param: {'learn_rate': 0.1}\n",
      "Mean score: 25.00    Std. dev.: 3.96    Param: {'learn_rate': 0.5}\n",
      "Mean score: 25.70    Std. dev.: 5.43    Param: {'learn_rate': 0.8}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1,0.5, 0.8]\n",
    "\n",
    "# grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(learn_rate = learning_rates))\n",
    "grid = GridSearchCV(estimator=model, cv=3, param_grid=dict(learn_rate = learning_rates))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)\n",
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, let's see an example of grid search for different types and degrees of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(regularizer = regularizers.l2(0.)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal',\n",
    "                   kernel_regularizer = regularizer))\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"SGD\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regularizer_list = [regularizers.l1(0.001), regularizers.l1(0.01), regularizers.l1(0.1), regularizers.l2(0.001), regularizers.l2(0.01), regularizers.l2(0.1)]\n",
    "#grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(regularizer = regularizer_list))\n",
    "grid = GridSearchCV(estimator=model, cv=3, param_grid=dict(regularizer = regularizer_list))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)\n",
    "#report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 23.67    Std. dev.: 4.93    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7fe22f473358>}\n",
      "Mean score: 23.77    Std. dev.: 4.82    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7fe22f4735f8>}\n",
      "Mean score: 25.33    Std. dev.: 4.83    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7fe22f4730f0>}\n",
      "Mean score: 23.48    Std. dev.: 4.91    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7fe22f4732e8>}\n",
      "Mean score: 23.82    Std. dev.: 4.71    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7fe22f473390>}\n",
      "Mean score: 26.41    Std. dev.: 5.58    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7fe22f4733c8>}\n"
     ]
    }
   ],
   "source": [
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
