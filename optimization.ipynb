{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization using Keras and the scikit-learn API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Keras, we can implement a grid search over hyperparameters using the scikit-learn API.\n",
    "\n",
    "We will demonstrate this using the original regression example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important hyperparameters for training\n",
    "\n",
    "- optimization algorithm\n",
    "- learning rate\n",
    "- dropout\n",
    "- regularization\n",
    "- batch size\n",
    "- number of training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As examples of grid search, we will explore varying optimizers, number of epochs, learning rate, and regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some housekeeping\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1 # for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, let's do a grid search over optimization algorithms.\n",
    "\n",
    "For some optimizers, dependent parameters can/should be tuned. We'll explore that later (by example).\n",
    "For most optimizers, it is in fact recommended to NOT change the defaults (e.g., RMSprop, Adagrad...)\n",
    "\n",
    "For now, the defaults will be used, e.g.\n",
    "- keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build_fn for keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params)\n",
    "def create_model(optimizer = \"Adam\"):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal')) # activation = None for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "optimizers = ['RMSprop', 'Adam', 'SGD']\n",
    "grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(optimizer = optimizers))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_cv_results(fit):\n",
    "    means = fit.cv_results_['mean_test_score']\n",
    "    sds = fit.cv_results_['std_test_score']\n",
    "    params = fit.cv_results_['params']\n",
    "    for mean, sd, param in zip(means, sds, params):\n",
    "        print(\"Mean score: {:.2f}    Std. dev.: {:.2f}    Param: {}\".format(mean, sd, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 539.61    Std. dev.: 60.88    Param: {'optimizer': 'RMSprop'}\n",
      "Mean score: 541.15    Std. dev.: 60.89    Param: {'optimizer': 'Adam'}\n",
      "Mean score: 21.42    Std. dev.: 7.57    Param: {'optimizer': 'SGD'}\n"
     ]
    }
   ],
   "source": [
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interestingly, with 50 epochs of training, SGD is _much_ better than the other algorithms! Let's check if Adam and RMSprop catch up with more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer = \"SGD\", epochs = num_epochs):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal')) # activation = None for regression\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 21.46    Std. dev.: 7.70    Param: {'epochs': 50, 'optimizer': 'SGD'}\n",
      "Mean score: 540.05    Std. dev.: 60.74    Param: {'epochs': 50, 'optimizer': 'RMSprop'}\n",
      "Mean score: 540.57    Std. dev.: 60.78    Param: {'epochs': 50, 'optimizer': 'Adam'}\n",
      "Mean score: 21.40    Std. dev.: 7.28    Param: {'epochs': 100, 'optimizer': 'SGD'}\n",
      "Mean score: 504.16    Std. dev.: 56.96    Param: {'epochs': 100, 'optimizer': 'RMSprop'}\n",
      "Mean score: 505.19    Std. dev.: 56.78    Param: {'epochs': 100, 'optimizer': 'Adam'}\n",
      "Mean score: 21.39    Std. dev.: 7.37    Param: {'epochs': 150, 'optimizer': 'SGD'}\n",
      "Mean score: 474.65    Std. dev.: 52.96    Param: {'epochs': 150, 'optimizer': 'RMSprop'}\n",
      "Mean score: 476.88    Std. dev.: 54.19    Param: {'epochs': 150, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "optimizers = ['SGD', 'RMSprop', 'Adam']\n",
    "epochs = [50,100,150]\n",
    "grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(optimizer = optimizers, epochs = epochs))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)\n",
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doesn't help. How about varying the learning rate for Adam (default is 0.001)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learn_rate = learning_rate):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal')) # activation = None for regression\n",
    "    optimizer = Adam(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 540.94    Std. dev.: 60.97    Param: {'learn_rate': 0.001}\n",
      "Mean score: 323.14    Std. dev.: 35.94    Param: {'learn_rate': 0.01}\n",
      "Mean score: 21.45    Std. dev.: 7.44    Param: {'learn_rate': 0.1}\n",
      "Mean score: 21.90    Std. dev.: 7.58    Param: {'learn_rate': 0.3}\n",
      "Mean score: 22.64    Std. dev.: 7.94    Param: {'learn_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1, 0.3, 0.5]\n",
    "grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(learn_rate = learning_rates))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)\n",
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, let's see an example of grid search for different types and degrees of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(regularizer = regularizers.l2(0.)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim , input_dim = input_dim, kernel_initializer='normal',\n",
    "                   kernel_regularizer = regularizer))\n",
    "    model.compile(loss='mean_squared_error', optimizer=\"SGD\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs = num_epochs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer_list = [regularizers.l1(0.001), regularizers.l1(0.01), regularizers.l1(0.1), regularizers.l2(0.001), regularizers.l2(0.01), regularizers.l2(0.1)]\n",
    "grid = GridSearchCV(estimator=model, cv=10, param_grid=dict(regularizer = regularizer_list))\n",
    "\n",
    "# do the grid search\n",
    "fit = grid.fit(X_train, y_train)\n",
    "#report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score: 21.56    Std. dev.: 7.63    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7f6a5974dcf8>}\n",
      "Mean score: 21.78    Std. dev.: 7.55    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7f6a5974dd30>}\n",
      "Mean score: 23.41    Std. dev.: 7.64    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7f6a5974dd68>}\n",
      "Mean score: 21.48    Std. dev.: 7.48    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7f6a5974dda0>}\n",
      "Mean score: 21.81    Std. dev.: 7.56    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7f6a5974ddd8>}\n",
      "Mean score: 24.64    Std. dev.: 8.09    Param: {'regularizer': <keras.regularizers.L1L2 object at 0x7f6a5974de10>}\n"
     ]
    }
   ],
   "source": [
    "report_cv_results(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
