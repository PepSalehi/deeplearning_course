{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM) with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an LSTM to generate text character by character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 128\n",
    "generate_len = 160\n",
    "\n",
    "seq_len = 30\n",
    "step = 3\n",
    "\n",
    "\n",
    "model_exists = False\n",
    "model_name = \"char_rnn_0.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Heading back to Washington, D.C. Much will be accomplished this week on trade, the military and security! Congratulations to Sung Hyun Park on winning the 2017 @USGA #USWomensOpen\\\\ud83c\\\\uddfa\\\\ud83c\\\\uddf8 I am at the @USGA  #USWomensOpen. An amateur player is co-leading for the first time in many decades - very exciting! The #USSJohnFinn will provide essential capabilities to keep America safe. Our sailors are the best anywhere in the world. Congratulations! https://t.co/yTnMwSh1Kg The ABC/Washington Post Poll, even though almost 40% is not bad at this time, was just about the most inaccurate poll around election time! With all of its phony unnamed sources &amp; highly slanted &amp; even fraudulent reporting, #Fake News is DISTORTING DEMOCRACY in our country! Thank you to former campaign adviser Michael Caputo for saying so powerfully that there was no Russian collusion in our winning campaign. Thank you to all of the supporters, who far out-numbered the protesters, yesterday at the Wom'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'text\": \"(.+?)\", \"created')\n",
    "\n",
    "# data downloaded from: https://github.com/bpb27/trump_tweet_data_archive\n",
    "with open('condensed_201567.json', 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "    #print(content[:1000])\n",
    "    tweets = re.findall(pattern, content)\n",
    "    \n",
    "print(len(tweets))\n",
    "\n",
    "text = \" \".join(tweets)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique chars: 92\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(set(text))\n",
    "print('Total unique chars:', len(unique_chars))\n",
    "char2index = dict((c, i) for i, c in enumerate(unique_chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(unique_chars))\n",
    "#char2index\n",
    "#index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sequences:  506092\n"
     ]
    }
   ],
   "source": [
    "# generate training data\n",
    "\n",
    "# this will yield X_train\n",
    "seqs = []\n",
    "# this will yield y_train\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    seqs.append(text[i: i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])\n",
    "print('Number of training sequences: ', len(seqs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heading back to Washington, D.',\n",
       " 'ding back to Washington, D.C. ',\n",
       " 'g back to Washington, D.C. Muc',\n",
       " 'ack to Washington, D.C. Much w',\n",
       " ' to Washington, D.C. Much will',\n",
       " ' Washington, D.C. Much will be',\n",
       " 'shington, D.C. Much will be ac',\n",
       " 'ngton, D.C. Much will be accom',\n",
       " 'on, D.C. Much will be accompli',\n",
       " ' D.C. Much will be accomplishe']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506092, 30, 92)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros((len(seqs), seq_len, len(unique_chars)), dtype=np.bool)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506092, 92)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((len(seqs), len(unique_chars)), dtype=np.bool)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill the X and y matrices, one-hot-encoding the characters\n",
    "# this yields the 57 features for the LSTM\n",
    "for i, s in enumerate(seqs):\n",
    "    for j, char in enumerate(s):\n",
    "        X[i, j, char2index[char]] = 1\n",
    "        y[i, char2index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               113152    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 92)                11868     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 92)                0         \n",
      "=================================================================\n",
      "Total params: 125,020\n",
      "Trainable params: 125,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if not model_exists:\n",
    "    model = Sequential()\n",
    "    # LSTM input is shaped (batch_size, timesteps, input_dim) where input_dim == number of features\n",
    "    model.add(LSTM(128, input_shape=(seq_len, len(unique_chars))))\n",
    "    model.add(Dense(len(unique_chars)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not model_exists:\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = preds.astype('float64')\n",
    "    #print(\"Original preds: {}\".format(preds))\n",
    "    preds = np.log(preds) / temperature\n",
    "    preds = np.exp(preds)\n",
    "    preds = preds / np.sum(preds)\n",
    "    #print(\"Adjusted preds: {}\".format(preds))\n",
    "    outcome = np.random.multinomial(1, preds, 1)\n",
    "    draw = np.argmax(outcome)\n",
    "    #print(\"Multinomial draw: {} - max index is {}\".format(outcome, draw))\n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrate sample function\n",
    "#preds = np.array([0.15, 0.2, 0.5, 0.15])\n",
    "\n",
    "#print(sample(preds, temperature = 0.2))\n",
    "#print(sample(preds, temperature = 0.5))\n",
    "#print(sample(preds, temperature = 1))\n",
    "#print(sample(preds, temperature = 1.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \n",
    "    # create seed for \n",
    "    start_index = random.randint(0, len(text) - seq_len - 1)\n",
    "    seed = text[start_index: start_index + seq_len]\n",
    "    print(\"####################################################################\")\n",
    "    print('#####    Seed: \"' + seed + '\"    #####')\n",
    "    print(\"####################################################################\")\n",
    "\n",
    "    for diversity in [0.05, 0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity, \" -----\")\n",
    "\n",
    "        generated = ''\n",
    "        seed = text[start_index: start_index + seq_len]\n",
    "        generated += seed\n",
    "\n",
    "        for i in range(generate_len):\n",
    "\n",
    "            # prepare the test input data\n",
    "            x = np.zeros((1, seq_len, len(unique_chars)))\n",
    "            for j, char in enumerate(seed):\n",
    "                x[0, j, char2index[char]] = 1.\n",
    "                \n",
    "            preds = model.predict(x)[0]\n",
    "            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = index2char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            seed = seed[1:] + next_char\n",
    "        print(generated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "Epoch 1/1\n",
      "506092/506092 [==============================] - 602s - loss: 1.9920   \n",
      "####################################################################\n",
      "#####    Seed: \" to ask the DNC 13 times for t\"    #####\n",
      "####################################################################\n",
      "\n",
      "----- diversity: 0.2  -----\n",
      " to ask the DNC 13 times for the problemed to the don't be at the problemed for the for and better the poll of the true to do a special the don't be and the don't be and and better to the co\n",
      "\n",
      "----- diversity: 0.5  -----\n",
      " to ask the DNC 13 times for the Watching you will be at the country, is so the are the doney but at Entruen a lore be presidential the wan with you anows at is is the believe to are never w\n",
      "\n",
      "----- diversity: 1.0  -----\n",
      " to ask the DNC 13 times for tonight'me sade to underatiams wthe every. Trump cournch tonight this callows tomust the dorntast sound auy lew a you.\\u2019s the bring watching for new it! #Tru\n",
      "\n",
      "----- diversity: 1.2  -----\n",
      " to ask the DNC 13 times for tonightMaalkeg\" aporenther! Tscoun True! #Trump: Coumo loses, I beggees tick, know\\\" \\\"@ll'tonnco9plalla1tSeaityint: I've loue Immemeched https://t.co/mkL49050Yp\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "506092/506092 [==============================] - 608s - loss: 1.7213   \n",
      "####################################################################\n",
      "#####    Seed: \"Scotland. What a great day, es\"    #####\n",
      "####################################################################\n",
      "\n",
      "----- diversity: 0.2  -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/key/software/anaconda3/envs/tf3.5/lib/python3.5/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scotland. What a great day, esporite and the polls to have the came the post of the Great on @realDonaldTrump will be in American the U.S. is the Marco Will need the was a strong to will be \n",
      "\n",
      "----- diversity: 0.5  -----\n",
      "Scotland. What a great day, espinditics what a book the media need the Money entreprenes and be thank you for this his a great the Trump to us stay on the Chicago I want to how to the does o\n",
      "\n",
      "----- diversity: 1.0  -----\n",
      "Scotland. What a great day, esighted to taxess ton\\u2019t or thank you. never down &amp; highly!!!!!\\\" \\\"@DegaryLeeC: @realDonaldTrump https://t.co/biGxU9p93E That is preferted!!menthornie r\n",
      "\n",
      "----- diversity: 1.2  -----\n",
      "Scotland. What a great day, esurttanceic DANA Grvan spentorment USE\\\" Now wow and American can Hopo, bixC\\nGeoksel... You freefs fulter cothering edending \\u201d@wallan6D2 one shournerently \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "506092/506092 [==============================] - 608s - loss: 1.6714   \n",
      "####################################################################\n",
      "#####    Seed: \" and the U.S. as a whole, I wi\"    #####\n",
      "####################################################################\n",
      "\n",
      "----- diversity: 0.2  -----\n",
      " and the U.S. as a whole, I will be in Republican of the world of the in the president that and a great and see the great and the great and get the politics is a great to be a great to have \n",
      "\n",
      "----- diversity: 0.5  -----\n",
      " and the U.S. as a whole, I will be this a all of the many for the lead Creason Berningtrate is such man hope the increase the with the consident! #Trump2016\\\" \\\"@IsweyEcc: @realDonaldTrump \n",
      "\n",
      "----- diversity: 1.0  -----\n",
      " and the U.S. as a whole, I will wince end @JimLaxBigting tell and Mondad! \\\"@WAcdTur: @realDonaldTrump co sap dishas owning .@FoxNews of with Javes Manyto how on \\\"@LaJphe those tolm in my \n",
      "\n",
      "----- diversity: 1.2  -----\n",
      " and the U.S. as a whole, I will 6-d my ydoel. A spocing in there dosbeedment 40t mil cunin neverfianthics.Eaces, can \\\"vet had weackersts ank hime-\\\"d. InhereecCone is no votendialle, great\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      "506092/506092 [==============================] - 614s - loss: 1.6450   \n",
      "####################################################################\n",
      "#####    Seed: \"onaldTrump is always kicking a\"    #####\n",
      "####################################################################\n",
      "\n",
      "----- diversity: 0.2  -----\n",
      "onaldTrump is always kicking and the true the new that the media and the true the real the real the true the start to the man be a beautiful to get the man and the man and the true! Thank yo\n",
      "\n",
      "----- diversity: 0.5  -----\n",
      "onaldTrump is always kicking and get ready of the true. Who is politicians are inserver be a country mind for and great at @realDonaldTrump be in Trump is the seevan with the politicians and\n",
      "\n",
      "----- diversity: 1.0  -----\n",
      "onaldTrump is always kicking athere it late. I have officite to fightity buy the senater watching on I'd border for leaving done\\\"\\\"\\\" hard rater should. - man! .@UntreeHas ost President Kag\n",
      "\n",
      "----- diversity: 1.2  -----\n",
      "onaldTrump is always kicking and #Dreanhand with bricks, fightiale manti NOUN! They be 7M9.lepo, Gunnation from So debatess for Excell get leads Gendialmberdod: \\\"Amentment! Having debate!\\\"\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/1\n",
      "506092/506092 [==============================] - 621s - loss: 1.6331   \n",
      "####################################################################\n",
      "#####    Seed: \"ple. \\u201cMake America Great \"    #####\n",
      "####################################################################\n",
      "\n",
      "----- diversity: 0.2  -----\n",
      "ple. \\u201cMake America Great Again! #MakeAmeraman America with the country to the many to his a business and the win to the with the America! #MakeAmerak America Great Again! #MakeAmeral #T\n",
      "\n",
      "----- diversity: 0.5  -----\n",
      "ple. \\u201cMake America Great Again! #trump2016\\\" \\\"@onierasis: @realDonaldTrump https://t.co/eXos1e5n31 https://t.co/Z7GU5fXMmJ https://t.co/Z7Q5WrQTy2 https://t.co/5yWmkb5IBA Thank you Joi\n",
      "\n",
      "----- diversity: 1.0  -----\n",
      "ple. \\u201cMake America Great Again He id\\\" Thank you both Cawit\\\" Hope @? https://t.co/pOU\\B5DYW: Cover gone. Araying at .@gretateomS, @replale  Great Spolitics and is dumBunguration of \\u2\n",
      "\n",
      "----- diversity: 1.2  -----\n",
      "ple. \\u201cMake America Great Again https://t.co/U5pU0YNRGT\\n\\nChe, Carafins 9J-ocMSFANGOAGRGHK! I cotting read avery  FAM inspy good we no deurl aw a Fol carely winc. Its PO. get one enion?\n"
     ]
    }
   ],
   "source": [
    "if not model_exists:\n",
    "\n",
    "    # train the model, output generated text after each iteration\n",
    "    for iteration in range(0, num_epochs):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(X, y,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=1)\n",
    "        model.save(\"char_rnn_{}.h5\".format(iteration))\n",
    "        generate()\n",
    "\n",
    "else:\n",
    "    model = load_model(model_name)\n",
    "    generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
