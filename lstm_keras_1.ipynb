{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM) with Keras (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use an LSTM to generate text character by character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_units = 128\n",
    "batch_size = 128\n",
    "generate_len = 160\n",
    "\n",
    "seq_len = 60\n",
    "step = 6\n",
    "\n",
    "model_exists = True\n",
    "model_name = \"char_rnn.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we're going to use are Trump's tweets from 01/2015 to 07/2017.\n",
    "The data have been downloaded from  https://github.com/bpb27/trump_tweet_data_archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Heading back to Washington, D.C. Much will be accomplished this week on trade, the military and security! Congratulations to Sung Hyun Park on winning the 2017 @USGA #USWomensOpen\\\\ud83c\\\\uddfa\\\\ud83c\\\\uddf8 I am at the @USGA  #USWomensOpen. An amateur player is co-leading for the first time in many decades - very exciting! The #USSJohnFinn will provide essential capabilities to keep America safe. Our sailors are the best anywhere in the world. Congratulations! https://t.co/yTnMwSh1Kg The ABC/Washington Post Poll, even though almost 40% is not bad at this time, was just about the most inaccurate poll around election time! With all of its phony unnamed sources &amp; highly slanted &amp; even fraudulent reporting, #Fake News is DISTORTING DEMOCRACY in our country! Thank you to former campaign adviser Michael Caputo for saying so powerfully that there was no Russian collusion in our winning campaign. Thank you to all of the supporters, who far out-numbered the protesters, yesterday at the Wom'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract text from the tweets and store everything in one long string\n",
    "import re\n",
    "pattern = re.compile(r'text\": \"(.+?)\", \"created')\n",
    "\n",
    "with open('condensed_201567.json', 'r') as content_file:\n",
    "    content = content_file.read()\n",
    "    #print(content[:1000])\n",
    "    tweets = re.findall(pattern, content)\n",
    "    \n",
    "print(len(tweets))\n",
    "\n",
    "text = \" \".join(tweets)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique chars: 92\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '#': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " '&': 6,\n",
       " \"'\": 7,\n",
       " '(': 8,\n",
       " ')': 9,\n",
       " '*': 10,\n",
       " '+': 11,\n",
       " ',': 12,\n",
       " '-': 13,\n",
       " '.': 14,\n",
       " '/': 15,\n",
       " '0': 16,\n",
       " '1': 17,\n",
       " '2': 18,\n",
       " '3': 19,\n",
       " '4': 20,\n",
       " '5': 21,\n",
       " '6': 22,\n",
       " '7': 23,\n",
       " '8': 24,\n",
       " '9': 25,\n",
       " ':': 26,\n",
       " ';': 27,\n",
       " '=': 28,\n",
       " '?': 29,\n",
       " '@': 30,\n",
       " 'A': 31,\n",
       " 'B': 32,\n",
       " 'C': 33,\n",
       " 'D': 34,\n",
       " 'E': 35,\n",
       " 'F': 36,\n",
       " 'G': 37,\n",
       " 'H': 38,\n",
       " 'I': 39,\n",
       " 'J': 40,\n",
       " 'K': 41,\n",
       " 'L': 42,\n",
       " 'M': 43,\n",
       " 'N': 44,\n",
       " 'O': 45,\n",
       " 'P': 46,\n",
       " 'Q': 47,\n",
       " 'R': 48,\n",
       " 'S': 49,\n",
       " 'T': 50,\n",
       " 'U': 51,\n",
       " 'V': 52,\n",
       " 'W': 53,\n",
       " 'X': 54,\n",
       " 'Y': 55,\n",
       " 'Z': 56,\n",
       " '[': 57,\n",
       " '\\\\': 58,\n",
       " ']': 59,\n",
       " '_': 60,\n",
       " '`': 61,\n",
       " 'a': 62,\n",
       " 'b': 63,\n",
       " 'c': 64,\n",
       " 'd': 65,\n",
       " 'e': 66,\n",
       " 'f': 67,\n",
       " 'g': 68,\n",
       " 'h': 69,\n",
       " 'i': 70,\n",
       " 'j': 71,\n",
       " 'k': 72,\n",
       " 'l': 73,\n",
       " 'm': 74,\n",
       " 'n': 75,\n",
       " 'o': 76,\n",
       " 'p': 77,\n",
       " 'q': 78,\n",
       " 'r': 79,\n",
       " 's': 80,\n",
       " 't': 81,\n",
       " 'u': 82,\n",
       " 'v': 83,\n",
       " 'w': 84,\n",
       " 'x': 85,\n",
       " 'y': 86,\n",
       " 'z': 87,\n",
       " '{': 88,\n",
       " '|': 89,\n",
       " '}': 90,\n",
       " '~': 91}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionaries for char -> index lookup and index -> char lookup, respectively\n",
    "unique_chars = sorted(set(text))\n",
    "print('Total unique chars:', len(unique_chars))\n",
    "char2index = dict((c, i) for i, c in enumerate(unique_chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(unique_chars))\n",
    "char2index\n",
    "#index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sequences:  253041\n"
     ]
    }
   ],
   "source": [
    "# generate training data\n",
    "# length of every sequence will be seq_len\n",
    "# degree of overlap is determined by step\n",
    "\n",
    "# this will yield X_train\n",
    "seqs = []\n",
    "# this will yield y_train\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    seqs.append(text[i: i + seq_len])\n",
    "    next_chars.append(text[i + seq_len])\n",
    "print('Number of training sequences: ', len(seqs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Heading back to Washington, D.C. Much will be accomplished t',\n",
       " 'g back to Washington, D.C. Much will be accomplished this we',\n",
       " ' to Washington, D.C. Much will be accomplished this week on ',\n",
       " 'shington, D.C. Much will be accomplished this week on trade,',\n",
       " 'on, D.C. Much will be accomplished this week on trade, the m',\n",
       " 'C. Much will be accomplished this week on trade, the militar',\n",
       " 'h will be accomplished this week on trade, the military and ',\n",
       " ' be accomplished this week on trade, the military and securi',\n",
       " 'complished this week on trade, the military and security! Co',\n",
       " 'shed this week on trade, the military and security! Congratu']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', 't', ' ', 'i', 'y', 's', 't', 'n', 'l']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253041, 60, 92)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the X and y matrices for training\n",
    "# X shape is (number of sequences, seq_len, number of unique characters(because of one-hot encoding))\n",
    "X = np.zeros((len(seqs), seq_len, len(unique_chars)), dtype=np.bool)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253041, 92)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y shape is (number of sequences,  number of unique characters)\n",
    "y = np.zeros((len(seqs), len(unique_chars)), dtype=np.bool)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill the X and y matrices, one-hot-encoding the characters\n",
    "# this yields the features (last dimension) for the LSTM\n",
    "for i, s in enumerate(seqs):\n",
    "    for j, char in enumerate(s):\n",
    "        X[i, j, char2index[char]] = 1\n",
    "        y[i, char2index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not model_exists:\n",
    "    model = Sequential()\n",
    "    # LSTM input is shaped (batch_size, timesteps, input_dim) where input_dim == number of features\n",
    "    model.add(LSTM(num_units, input_shape=(seq_len, len(unique_chars))))\n",
    "    model.add(Dense(len(unique_chars)))\n",
    "    # the model's output will be class probabilities for the different characters, from which we can sample to generate a successor\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not model_exists:\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function allows for manipulating the \"raw probabilities\" returned by the network\n",
    "# temperature > 1 enhances likelihood for low-probability characters\n",
    "# temperature < 1 favors high-probability characters disproportionately\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = preds.astype('float64')\n",
    "    #print(\"Original preds: {}\".format(preds))\n",
    "    preds = np.log(preds) / temperature\n",
    "    preds = np.exp(preds)\n",
    "    preds = preds / (np.sum(preds) + 0.000000000001)\n",
    "    #print(\"Adjusted preds: {}\".format(preds))\n",
    "    outcome = np.random.multinomial(1, preds, 1)\n",
    "    draw = np.argmax(outcome)\n",
    "    #print(\"Multinomial draw: {} - max index is {}\".format(outcome, draw))\n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# illustrate sample function\n",
    "preds = np.array([0.15, 0.2, 0.5, 0.15])\n",
    "\n",
    "print(sample(preds, temperature = 0.2))\n",
    "print(sample(preds, temperature = 0.5))\n",
    "print(sample(preds, temperature = 1))\n",
    "print(sample(preds, temperature = 1.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate text after every epoch, to allow for comparisons\n",
    "# For every epoch, text is generated using different temperatures/diversities\n",
    "def generate():\n",
    "    \n",
    "    # create seed for generation\n",
    "    start_index = random.randint(0, len(text) - seq_len - 1)\n",
    "    seed = text[start_index: start_index + seq_len]\n",
    "    print(\"####################################################################\")\n",
    "    print('#####    Seed: \"' + seed + '\"    #####')\n",
    "    print(\"####################################################################\")\n",
    "\n",
    "    for diversity in [0.1, 0.3, 0.6, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity, \" -----\")\n",
    "\n",
    "        generated = ''\n",
    "        seed = text[start_index: start_index + seq_len]\n",
    "        generated += seed\n",
    "\n",
    "        for i in range(generate_len):\n",
    "\n",
    "            # prepare the test input data\n",
    "            x = np.zeros((1, seq_len, len(unique_chars)))\n",
    "            for j, char in enumerate(seed):\n",
    "                x[0, j, char2index[char]] = 1.\n",
    "                \n",
    "            preds = model.predict(x)[0]\n",
    "            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = index2char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            seed = seed[1:] + next_char\n",
    "        print(generated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################\n",
      "#####    Seed: \" a game Changer!  WATCH! \\\"@craig_eaton12: @realDonaldTrump \"    #####\n",
      "####################################################################\n",
      "\n",
      "----- diversity: 0.1  -----\n",
      " a game Changer!  WATCH! \\\"@craig_eaton12: @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDo\n",
      "\n",
      "----- diversity: 0.3  -----\n",
      " a game Changer!  WATCH! \\\"@craig_eaton12: @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump @realDonaldTrump The poll to be should be striel to show about @realDonaldTrump @realDonaldT\n",
      "\n",
      "----- diversity: 0.6  -----\n",
      " a game Changer!  WATCH! \\\"@craig_eaton12: @realDonaldTrump Not the properting it will to have the oral U.S. Today is going to be off to is a truth st jDOCAED Chinaz Amazing Trump all the only in bass!\\\" \\\"@catebllaman: \n",
      "\n",
      "----- diversity: 1.0  -----\n",
      " a game Changer!  WATCH! \\\"@craig_eaton12: @realDonaldTrump #National The  Nedua this so so about it then Cc. Trump lile for with Davest overs placederandon other jump ie, its was Millian stead on Jindanis me. I Sorril s\n",
      "\n",
      "----- diversity: 1.2  -----\n",
      " a game Changer!  WATCH! \\\"@craig_eaton12: @realDonaldTrump @JohnForligatRMmAarc I GREAT AGABE!\\u2014and bringan! @FoxDisay &amp; Ylam's out Corley Fundarly ny CNH'I stame T the a viraes asb, backed to Selue! Turn GrazT!\n"
     ]
    }
   ],
   "source": [
    "if not model_exists:\n",
    "\n",
    "    # train the model, output generated text after each iteration to see how it evolves\n",
    "    for iteration in range(0, num_epochs):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(X, y,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=1)\n",
    "        model.save(\"char_rnn_{}.h5\".format(iteration))\n",
    "        generate()\n",
    "\n",
    "else:\n",
    "    model = load_model(model_name)\n",
    "    generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
