{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks with Keras (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatives when using a pre-trained network:\n",
    "\n",
    "- Just use softmax predictions for the new data. Only makes sense when new data have known classes.\n",
    "- Use the bottleneck features (activations from last MaxPooling layer before fully connected layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1) instantiate convolutional part of the model (everything up to the fully-connected layers) and run this model on the training and test data once, recording the output (the \"bottleneck features\", i.e. the last activation maps before the fully-connected layers) in two numpy arrays\n",
    "\n",
    "2) train a small fully-connected model on top of the stored features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 375,500\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "test_data_dir = 'data/test'\n",
    "\n",
    "n_train_samples = 235\n",
    "n_train_ants = 114\n",
    "n_train_bees = 121\n",
    "\n",
    "\n",
    "n_test_samples = 148\n",
    "n_test_ants = 66\n",
    "n_test_bees = 82\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "bottleneck_features_train_path = \"bottleneck_features_train.npy\"\n",
    "bottleneck_features_test_path = \"bottleneck_features_test.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: save bottleneck features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why we are storing the features offline rather than adding our fully-connected model directly on top of a frozen convolutional base and running the whole thing, is computational effiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 235 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# no data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# training data\n",
    "generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None, # no labels\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network\n",
    "model = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 734s    \n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_train = model.predict_generator(generator, n_train_samples//batch_size+1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 11, 15, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(bottleneck_features_train_path, bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 images belonging to 2 classes.\n",
      "10/10 [==============================] - 469s    \n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "bottleneck_features_test = model.predict_generator(generator,n_test_samples // batch_size + 1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(148, 11, 15, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(bottleneck_features_test_path, bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: load saved data and train a small fully-connected model on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((235,), (235, 11, 15, 512))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(bottleneck_features_train_path)\n",
    "train_labels = np.array([0] * n_train_ants + [1] * n_train_bees)\n",
    "train_labels.shape, train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((148,), (148, 11, 15, 512))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.load(bottleneck_features_test_path)\n",
    "test_labels = np.array([0] * n_test_ants + [1] * n_test_bees)\n",
    "test_labels.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 84480)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               21627136  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 21,627,393\n",
      "Trainable params: 21,627,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 148 samples\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 4s - loss: 7.3266 - acc: 0.5106 - val_loss: 7.1094 - val_acc: 0.5541\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 4s - loss: 7.7338 - acc: 0.5149 - val_loss: 7.1094 - val_acc: 0.5541\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 4s - loss: 7.7338 - acc: 0.5149 - val_loss: 7.1094 - val_acc: 0.5541\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 4s - loss: 7.7338 - acc: 0.5149 - val_loss: 7.1094 - val_acc: 0.5541\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 4s - loss: 7.7338 - acc: 0.5149 - val_loss: 7.1094 - val_acc: 0.5541\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 4s - loss: 7.7270 - acc: 0.5149 - val_loss: 7.1094 - val_acc: 0.5541\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 4s - loss: 7.0320 - acc: 0.5277 - val_loss: 8.9303 - val_acc: 0.4459\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 4s - loss: 6.3234 - acc: 0.5532 - val_loss: 2.0003 - val_acc: 0.7365\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 5s - loss: 5.6319 - acc: 0.5915 - val_loss: 2.9173 - val_acc: 0.6892\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 4s - loss: 4.8994 - acc: 0.6213 - val_loss: 2.4067 - val_acc: 0.7905\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 4s - loss: 3.4051 - acc: 0.7319 - val_loss: 6.8735 - val_acc: 0.5270\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 5s - loss: 3.8938 - acc: 0.6979 - val_loss: 2.3323 - val_acc: 0.7838\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 4s - loss: 2.4836 - acc: 0.8000 - val_loss: 2.7589 - val_acc: 0.7703\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 4s - loss: 1.8351 - acc: 0.8511 - val_loss: 2.0877 - val_acc: 0.8108\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 4s - loss: 2.9951 - acc: 0.7489 - val_loss: 3.5281 - val_acc: 0.7365\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 4s - loss: 1.6322 - acc: 0.8553 - val_loss: 2.3302 - val_acc: 0.7973\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 4s - loss: 1.4371 - acc: 0.8766 - val_loss: 2.7783 - val_acc: 0.7770\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 4s - loss: 1.9700 - acc: 0.8170 - val_loss: 2.6538 - val_acc: 0.7905\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 4s - loss: 1.1868 - acc: 0.9021 - val_loss: 2.3343 - val_acc: 0.7905\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 4s - loss: 1.3035 - acc: 0.8723 - val_loss: 2.1405 - val_acc: 0.7905\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 4s - loss: 0.4363 - acc: 0.9574 - val_loss: 1.8686 - val_acc: 0.8176\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 4s - loss: 1.0566 - acc: 0.9064 - val_loss: 2.7250 - val_acc: 0.7770\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 4s - loss: 1.2137 - acc: 0.8766 - val_loss: 1.7588 - val_acc: 0.8514\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 4s - loss: 0.4713 - acc: 0.9532 - val_loss: 1.8583 - val_acc: 0.8041\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 4s - loss: 0.7779 - acc: 0.9064 - val_loss: 1.6518 - val_acc: 0.8649\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 4s - loss: 0.5015 - acc: 0.9532 - val_loss: 1.8671 - val_acc: 0.8108\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 4s - loss: 0.3993 - acc: 0.9617 - val_loss: 1.5922 - val_acc: 0.8649\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 4s - loss: 0.6348 - acc: 0.9234 - val_loss: 1.6232 - val_acc: 0.8716\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 4s - loss: 0.2676 - acc: 0.9617 - val_loss: 1.9785 - val_acc: 0.8108\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 4s - loss: 0.3943 - acc: 0.9574 - val_loss: 2.5752 - val_acc: 0.7432\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 4s - loss: 0.2701 - acc: 0.9574 - val_loss: 1.8595 - val_acc: 0.8378\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 4s - loss: 0.2631 - acc: 0.9787 - val_loss: 1.5836 - val_acc: 0.8649\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 4s - loss: 0.5086 - acc: 0.9362 - val_loss: 1.8439 - val_acc: 0.8446\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 4s - loss: 0.1384 - acc: 0.9915 - val_loss: 1.5780 - val_acc: 0.8649\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 4s - loss: 0.3991 - acc: 0.9660 - val_loss: 1.8539 - val_acc: 0.8446\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 4s - loss: 0.0683 - acc: 0.9957 - val_loss: 1.7771 - val_acc: 0.8446\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 4s - loss: 0.7556 - acc: 0.9319 - val_loss: 1.8985 - val_acc: 0.8311\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 4s - loss: 0.1918 - acc: 0.9872 - val_loss: 1.6869 - val_acc: 0.8514\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 4s - loss: 0.2741 - acc: 0.9660 - val_loss: 1.6320 - val_acc: 0.8514\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 4s - loss: 0.1044 - acc: 0.9915 - val_loss: 2.2633 - val_acc: 0.7905\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 4s - loss: 0.1800 - acc: 0.9660 - val_loss: 1.7043 - val_acc: 0.8311\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 4s - loss: 0.0745 - acc: 0.9915 - val_loss: 1.6087 - val_acc: 0.8581\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 4s - loss: 0.1007 - acc: 0.9915 - val_loss: 2.4948 - val_acc: 0.7770\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 4s - loss: 0.3194 - acc: 0.9617 - val_loss: 2.0772 - val_acc: 0.7838\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 4s - loss: 0.0684 - acc: 0.9957 - val_loss: 1.6965 - val_acc: 0.8446\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 4s - loss: 0.0679 - acc: 0.9957 - val_loss: 1.6735 - val_acc: 0.8649\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 4s - loss: 0.0679 - acc: 0.9957 - val_loss: 1.6788 - val_acc: 0.8649\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 4s - loss: 0.0678 - acc: 0.9957 - val_loss: 1.6840 - val_acc: 0.8649\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 4s - loss: 0.0678 - acc: 0.9957 - val_loss: 1.7387 - val_acc: 0.8446\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 4s - loss: 0.1328 - acc: 0.9872 - val_loss: 5.3539 - val_acc: 0.6149\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, train_labels,\n",
    "              epochs=num_epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(test_data, test_labels))\n",
    "model.save_weights(top_model_weights_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "At this time, there is no overall model that could be used for new predictions.\n",
    "\n",
    "This will be addressed in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
